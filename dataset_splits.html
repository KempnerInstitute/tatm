

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Dataset Splitting &mdash; tatm  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Metadata Store Setup" href="admin_docs/metadata_store_setup.html" />
    <link rel="prev" title="Dataset Metadata" href="metadata.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            tatm
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Package Configuration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="text_dataset.html">Loading Text Data for LLM Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="metadata.html">Dataset Metadata</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Dataset Splitting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#example-loading-a-dataset-and-splitting-it-into-training-and-validation-sets">Example loading a dataset and splitting it into training and validation sets</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Administration:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="admin_docs/metadata_store_setup.html">Metadata Store Setup</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_docs/cli.html"><code class="docutils literal notranslate"><span class="pre">tatm</span></code> CLI Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_docs/data_api.html"><code class="docutils literal notranslate"><span class="pre">tatm.data</span></code> Data Module API</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_docs/config_api.html"><code class="docutils literal notranslate"><span class="pre">tatm.config</span></code> Config API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_docs/tokenizer_api.html"><code class="docutils literal notranslate"><span class="pre">tatm.tokenizer</span></code> Tokenizer API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_docs/metadata_store_api.html">Metadata Store API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">tatm</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Dataset Splitting</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/dataset_splits.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="dataset-splitting">
<h1>Dataset Splitting<a class="headerlink" href="#dataset-splitting" title="Link to this heading"></a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">TatmDataset</span></code> class includes functionality for creating simple index based train and validation scripts
that can be used to separate the dataset into training and validation sets. The functionality as implemented
allows for users to either specify a number of indices or a percentage of the dataset to be used for validation.
The split will be deterministic based on the index in the full dataset and will not change between runs or if the
same dataset is loaded multiple times.</p>
<section id="example-loading-a-dataset-and-splitting-it-into-training-and-validation-sets">
<h2>Example loading a dataset and splitting it into training and validation sets<a class="headerlink" href="#example-loading-a-dataset-and-splitting-it-into-training-and-validation-sets" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tatm</span> <span class="kn">import</span> <span class="n">get_dataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;my_data&quot;</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">val_split_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 1000</span>

</pre></div>
</div>
<p>The proceeding code will load the dataset and tell the dataset object to prepare to split the dataset into a training
and validation set where the validation set will be 10% of the full dataset. However if we call <code class="docutils literal notranslate"><span class="pre">len</span></code> on the dataset
at this point we will see that the dataset is still the full dataset.</p>
<p>If we want to use the training set for the split we have two possible approaches. The first is to call the <code class="docutils literal notranslate"><span class="pre">set_split</span></code>
method on the dataset object and pass in the string “train” as the argument. The second is to pass “train” as the
split argument when initializing the dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 900</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;my_data&quot;</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">val_split_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>
<span class="c1"># 900</span>
</pre></div>
</div>
<p>We can also use the same approach to get the validation set.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 100</span>

<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;my_data&quot;</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">val_split_size</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span> <span class="c1"># we can also pass in a number of items to use for the validation set</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">))</span>
<span class="c1"># 150</span>
</pre></div>
</div>
<p>Note that we can use the <code class="docutils literal notranslate"><span class="pre">set_split</span></code> method to switch between the training and validation sets at any time. If we want to operate on the full dataset we can call <code class="docutils literal notranslate"><span class="pre">set_split(None)</span></code> or pass <code class="docutils literal notranslate"><span class="pre">None</span></code> as the split argument when initializing the dataset. If we have loaded a dataset without defining a split size, we can still create a split by calling the <code class="docutils literal notranslate"><span class="pre">create_split</span></code> method and passing in the desired split size. This will create a new split based on the current dataset and the specified split size. Note that this has to be done prior to calling <code class="docutils literal notranslate"><span class="pre">set_split</span></code> or passing in a split argument when initializing the dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;my_data&quot;</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 1000</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">create_split</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># create a split with 10% of the dataset reserved for validation</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 1000</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 900</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 100</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># set the split to None to use the full dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="c1"># 1000</span>
</pre></div>
</div>
<p>When we have the splits created, the indices used to return items in the dataset will be remapped to only return items from the split that we are using. Note that
this also means in the case of the validation split, indices will be remapped so that the first index in the validation split can be returned by calling <code class="docutils literal notranslate"><span class="pre">dataset[0]</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;my_data&quot;</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">val_split_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;my_data&quot;</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">val_split_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">800</span><span class="p">]</span> <span class="o">==</span> <span class="n">val_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># True</span>
</pre></div>
</div>
<p>With these features in place, we can easily create training and validation sets for our dataset and use them in training and evaluation loops as drop in replacements for the full dataset.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="metadata.html" class="btn btn-neutral float-left" title="Dataset Metadata" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="admin_docs/metadata_store_setup.html" class="btn btn-neutral float-right" title="Metadata Store Setup" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Kempner Institute at Harvard University.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>